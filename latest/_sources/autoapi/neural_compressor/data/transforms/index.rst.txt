:py:mod:`neural_compressor.data.transforms`
===========================================

.. py:module:: neural_compressor.data.transforms

.. autoapi-nested-parse::

   Neural Compressor Built-in transforms for multiple framework backends.



Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   imagenet_transform/index.rst
   postprocess/index.rst
   tokenization/index.rst
   transform/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   neural_compressor.data.transforms.TRANSFORMS
   neural_compressor.data.transforms.BaseTransform
   neural_compressor.data.transforms.ComposeTransform
   neural_compressor.data.transforms.ResizeTFTransform
   neural_compressor.data.transforms.TensorflowResizeWithRatio
   neural_compressor.data.transforms.RescaleTFTransform
   neural_compressor.data.transforms.NormalizeTFTransform
   neural_compressor.data.transforms.TFSquadV1PostTransform
   neural_compressor.data.transforms.TFSquadV1ModelZooPostTransform
   neural_compressor.data.transforms.ParseDecodeCocoTransform
   neural_compressor.data.transforms.Postprocess
   neural_compressor.data.transforms.LabelShift
   neural_compressor.data.transforms.BilinearImagenetTransform
   neural_compressor.data.transforms.TensorflowResizeCropImagenetTransform



Functions
~~~~~~~~~

.. autoapisummary::

   neural_compressor.data.transforms.transform_registry



.. py:class:: TRANSFORMS(framework, process)

   Bases: :py:obj:`object`

   Transforms collection class.

   Provide register method to register new Transforms
   and provide __getitem__ method to get Transforms according to Transforms type.

   .. py:method:: register(name, transform_cls)

      Register new Transform according to Transforms type.

      :param name: process name
      :type name: str
      :param transform_cls: process function wrapper class
      :type transform_cls: class



.. py:class:: BaseTransform

   Bases: :py:obj:`object`

   The base class for transform.


.. py:class:: ComposeTransform(transform_list)

   Bases: :py:obj:`BaseTransform`

   Composes several transforms together.

   :param transform_list: list of transforms to compose
   :type transform_list: list of Transform objects

   :returns: tuple of processed image and label
   :rtype: sample (tuple)


.. py:function:: transform_registry(transform_type, process, framework)

   Class decorator used to register all transform subclasses.

   :param transform_type: Transform registration name
   :type transform_type: str
   :param process: support 3 process including 'preprocess', 'postprocess', 'general'
   :type process: str
   :param framework: support 4 framework including 'tensorflow', 'pytorch', 'mxnet', 'onnxrt'
   :type framework: str
   :param cls: The class of register.
   :type cls: class

   :returns: The class of register.
   :rtype: cls


.. py:class:: ResizeTFTransform(size, interpolation='bilinear')

   Bases: :py:obj:`BaseTransform`

   Resize the input image to the given size.

   :param size: Size of the result
   :type size: list or int
   :param interpolation: Desired interpolation type,
                         support 'bilinear', 'nearest', 'bicubic'
   :type interpolation: str, default='bilinear'

   :returns: tuple of processed image and label


.. py:class:: TensorflowResizeWithRatio(min_dim=800, max_dim=1365, padding=False, constant_value=0)

   Bases: :py:obj:`BaseTransform`

   Resize image with aspect ratio and pad it to max shape(optional).

   If the image is padded, the label will be processed at the same time.
   The input image should be np.array or tf.Tensor.

   :param min_dim: Resizes the image such that its smaller dimension == min_dim
   :type min_dim: int, default=800
   :param max_dim: Ensures that the image longest side doesn't exceed this value
   :type max_dim: int, default=1365
   :param padding: If true, pads image with zeros so its size is max_dim x max_dim
   :type padding: bool, default=False

   :returns: tuple of processed image and label


.. py:class:: RescaleTFTransform

   Bases: :py:obj:`BaseTransform`

   Scale the values of image to [0,1].

   :returns: tuple of processed image and label


.. py:class:: NormalizeTFTransform(mean=[0.0], std=[1.0], rescale=None)

   Bases: :py:obj:`BaseTransform`

   Normalize a image with mean and standard deviation.

   :param mean: means for each channel, if len(mean)=1, mean will be broadcasted to each channel,
                otherwise its length should be same with the length of image shape
   :type mean: list, default=[0.0]
   :param std: stds for each channel, if len(std)=1, std will be broadcasted to each channel,
               otherwise its length should be same with the length of image shape
   :type std: list, default=[1.0]

   :returns: tuple of processed image and label


.. py:class:: TFSquadV1PostTransform(label_file, vocab_file, n_best_size=20, max_seq_length=384, max_query_length=64, max_answer_length=30, do_lower_case=True, doc_stride=128)

   Bases: :py:obj:`BaseTransform`

   Postprocess the predictions of bert on SQuAD.

   :param label_file: path of label file
   :type label_file: str
   :param vocab_file: path of vocabulary file
   :type vocab_file: str
   :param n_best_size: The total number of n-best predictions to generate in nbest_predictions.json
   :type n_best_size: int, default=20
   :param max_seq_length: The maximum total input sequence length after WordPiece tokenization.
                          Sequences longer than this will be truncated, shorter than this will be padded
   :type max_seq_length: int, default=384
   :param max_query_length: The maximum number of tokens for the question.
                            Questions longer than this will be truncated to this length
   :type max_query_length: int, default=64
   :param max_answer_length: The maximum length of an answer that can be generated. This is needed because
                             the start and end predictions are not conditioned on one another
   :type max_answer_length: int, default=30
   :param do_lower_case: Whether to lower case the input text.
                         Should be True for uncased models and False for cased models
   :type do_lower_case: bool, default=True
   :param doc_stride: When splitting up a long document into chunks,
                      how much stride to take between chunks
   :type doc_stride: int, default=128

   :returns: tuple of processed prediction and label

   .. py:method:: process_result(results)

      Get the processed results.


   .. py:method:: get_postprocess_result(sample)

      Get the post processed results.



.. py:class:: TFSquadV1ModelZooPostTransform(label_file, vocab_file, n_best_size=20, max_seq_length=384, max_query_length=64, max_answer_length=30, do_lower_case=True, doc_stride=128)

   Bases: :py:obj:`TFSquadV1PostTransform`

   Postprocess the predictions of bert on SQuADV1.1.

   See class TFSquadV1PostTransform for more details


.. py:class:: ParseDecodeCocoTransform

   Bases: :py:obj:`neural_compressor.experimental.data.transforms.BaseTransform`

   Coco decoding will be performed automatically from Neural Compressor v1.4.



.. py:class:: Postprocess(postprocess_cls, name='user_postprocess', **kwargs)

   Bases: :py:obj:`object`

   Just collect the infos to construct a Postprocess.


.. py:class:: LabelShift(label_shift=0)

   Bases: :py:obj:`neural_compressor.data.transforms.transform.BaseTransform`

   Convert label to label - label_shift.

   :param label_shift: number of label shift
   :type label_shift: int, default=0

   :returns: tuple of processed image and label


.. py:class:: BilinearImagenetTransform(height, width, central_fraction=0.875, mean_value=[0.0, 0.0, 0.0], scale=1.0)

   Bases: :py:obj:`neural_compressor.data.transforms.transform.BaseTransform`

   Combination of a series of transforms which is applicable to images in Imagenet.

   :param height: Height of the result
   :param width: Width of the result
   :param central_fraction: fraction of size to crop
   :type central_fraction: float, default=0.875
   :param mean_value: means for each channel
   :type mean_value: list, default=[0.0,0.0,0.0]
   :param scale: std value
   :type scale: float, default=1.0

   :returns: tuple of processed image and label


.. py:class:: TensorflowResizeCropImagenetTransform(height, width, random_crop=False, resize_side=256, resize_method='bilinear', random_flip_left_right=False, mean_value=[0.0, 0.0, 0.0], scale=1.0, data_format='channels_last', subpixels='RGB')

   Bases: :py:obj:`neural_compressor.data.transforms.transform.BaseTransform`

   Combination of a series of transforms which is applicable to images in Imagenet.

   :param height: Height of the result
   :type height: int
   :param width: Width of the result
   :type width: int
   :param random_crop: whether to random crop
   :type random_crop: bool, default=False
   :param resize_side: desired shape after resize operation
   :type resize_side: int, default=256
   :param random_flip_left_right: whether to random flip left and right
   :type random_flip_left_right: bool, default=False
   :param mean_value: means for each channel
   :type mean_value: list, default=[0.0,0.0,0.0]
   :param scale: std value
   :type scale: float, default=1.0

   :returns: tuple of processed image and label


