:py:mod:`neural_compressor.data`
================================

.. py:module:: neural_compressor.data

.. autoapi-nested-parse::

   Built-in dataloaders, datasets, transforms, filters for multiple framework backends.



Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   datasets/index.rst
   filters/index.rst
   transforms/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   neural_compressor.data.Datasets
   neural_compressor.data.Dataset
   neural_compressor.data.IterableDataset
   neural_compressor.data.TensorflowImageRecord
   neural_compressor.data.COCORecordDataset
   neural_compressor.data.DataLoader
   neural_compressor.data.DefaultDataLoader
   neural_compressor.data.TRANSFORMS
   neural_compressor.data.BaseTransform
   neural_compressor.data.ComposeTransform
   neural_compressor.data.Postprocess
   neural_compressor.data.LabelShift
   neural_compressor.data.BilinearImagenetTransform
   neural_compressor.data.TensorflowResizeCropImagenetTransform
   neural_compressor.data.TFSquadV1PostTransform
   neural_compressor.data.TFSquadV1ModelZooPostTransform
   neural_compressor.data.TensorflowResizeWithRatio
   neural_compressor.data.ResizeTFTransform
   neural_compressor.data.RescaleTFTransform
   neural_compressor.data.NormalizeTFTransform
   neural_compressor.data.ParseDecodeCocoTransform
   neural_compressor.data.FILTERS
   neural_compressor.data.Filter
   neural_compressor.data.LabelBalanceCOCORecordFilter



Functions
~~~~~~~~~

.. autoapisummary::

   neural_compressor.data.dataset_registry
   neural_compressor.data.transform_registry
   neural_compressor.data.filter_registry



Attributes
~~~~~~~~~~

.. autoapisummary::

   neural_compressor.data.DATALOADERS


.. py:class:: Datasets(framework)

   Bases: :py:obj:`object`

   A base class for all framework datasets.

   :param framework: framework name, like:"tensorflow", "tensorflow_itex",
                     "mxnet", "onnxrt_qdq", "onnxrt_qlinearops", "onnxrt_integerops",
                     "pytorch", "pytorch_ipex", "pytorch_fx", "onnxruntime".
   :type framework: str


.. py:class:: Dataset

   Bases: :py:obj:`object`

   The base class of dataset.

   Subclass datasets should overwrite two methods:
   `__getitem__` for indexing to data sample and `__len__`for the size of the dataset


.. py:class:: IterableDataset

   Bases: :py:obj:`object`

   An iterable Dataset.

   Subclass iterable dataset should also implement a method:
   `__iter__` for interating over the samples of the dataset.


.. py:function:: dataset_registry(dataset_type, framework, dataset_format='')

   Register dataset subclasses.

   :param cls: The class of register.
   :type cls: class
   :param dataset_type: The dataset registration name
   :type dataset_type: str
   :param framework: support 3 framework including 'tensorflow', 'pytorch', 'mxnet'
   :type framework: str
   :param data_format: The format dataset saved, eg 'raw_image', 'tfrecord'
   :type data_format: str

   :returns: The class of register.
   :rtype: cls


.. py:class:: TensorflowImageRecord

   Bases: :py:obj:`IterableDataset`

   Tensorflow imageNet database in tf record format.

   Please arrange data in this way:
       root/validation-000-of-100
       root/validation-001-of-100
       ...
       root/validation-099-of-100
   The file name needs to follow this pattern: '* - * -of- *'

   Args: root (str): Root directory of dataset.
         transform (transform object, default=None):  transform to process input data.
         filter (Filter objects, default=None): filter out examples according
                                                to specific conditions.


.. py:class:: COCORecordDataset

   Bases: :py:obj:`neural_compressor.data.datasets.dataset.IterableDataset`

   Tensorflow COCO dataset in tf record format.

   Root is a full path to tfrecord file, which contains the file name.
   Please use Resize transform when batch_size > 1

   Args: root (str): Root directory of dataset.
         num_cores (int, default=28):The number of input Datasets to interleave from in parallel.
         transform (transform object, default=None):  transform to process input data.
         filter (Filter objects, default=None): filter out examples according
                                                to specific conditions.



.. py:class:: DataLoader

   Bases: :py:obj:`object`

   Entrance of all configured DataLoaders. Will dispatch the DataLoaders to framework
   specific one. Users will be not aware of the dispatching, and the Interface is unified.


.. py:class:: DefaultDataLoader(dataset, batch_size=1, last_batch='rollover', collate_fn=None, sampler=None, batch_sampler=None, num_workers=0, pin_memory=False, shuffle=False, distributed=False)

   Bases: :py:obj:`neural_compressor.data.dataloaders.base_dataloader.BaseDataLoader`

   DefaultDataLoader for multiple framework backends.

   .. py:property:: dataloader

      Return dataloader.

   .. py:method:: batch(batch_size, last_batch='rollover')

      Set batch_size and last_batch.



.. py:class:: TRANSFORMS(framework, process)

   Bases: :py:obj:`object`

   Transforms collection class.

   Provide register method to register new Transforms
   and provide __getitem__ method to get Transforms according to Transforms type.

   .. py:method:: register(name, transform_cls)

      Register new Transform according to Transforms type.

      :param name: process name
      :type name: str
      :param transform_cls: process function wrapper class
      :type transform_cls: class



.. py:class:: BaseTransform

   Bases: :py:obj:`object`

   The base class for transform.


.. py:class:: ComposeTransform(transform_list)

   Bases: :py:obj:`BaseTransform`

   Composes several transforms together.

   :param transform_list: list of transforms to compose
   :type transform_list: list of Transform objects

   :returns: tuple of processed image and label
   :rtype: sample (tuple)


.. py:function:: transform_registry(transform_type, process, framework)

   Class decorator used to register all transform subclasses.

   :param transform_type: Transform registration name
   :type transform_type: str
   :param process: support 3 process including 'preprocess', 'postprocess', 'general'
   :type process: str
   :param framework: support 4 framework including 'tensorflow', 'pytorch', 'mxnet', 'onnxrt'
   :type framework: str
   :param cls: The class of register.
   :type cls: class

   :returns: The class of register.
   :rtype: cls


.. py:class:: Postprocess(postprocess_cls, name='user_postprocess', **kwargs)

   Bases: :py:obj:`object`

   Just collect the infos to construct a Postprocess.


.. py:class:: LabelShift(label_shift=0)

   Bases: :py:obj:`neural_compressor.data.transforms.transform.BaseTransform`

   Convert label to label - label_shift.

   :param label_shift: number of label shift
   :type label_shift: int, default=0

   :returns: tuple of processed image and label


.. py:class:: BilinearImagenetTransform(height, width, central_fraction=0.875, mean_value=[0.0, 0.0, 0.0], scale=1.0)

   Bases: :py:obj:`neural_compressor.data.transforms.transform.BaseTransform`

   Combination of a series of transforms which is applicable to images in Imagenet.

   :param height: Height of the result
   :param width: Width of the result
   :param central_fraction: fraction of size to crop
   :type central_fraction: float, default=0.875
   :param mean_value: means for each channel
   :type mean_value: list, default=[0.0,0.0,0.0]
   :param scale: std value
   :type scale: float, default=1.0

   :returns: tuple of processed image and label


.. py:class:: TensorflowResizeCropImagenetTransform(height, width, random_crop=False, resize_side=256, resize_method='bilinear', random_flip_left_right=False, mean_value=[0.0, 0.0, 0.0], scale=1.0, data_format='channels_last', subpixels='RGB')

   Bases: :py:obj:`neural_compressor.data.transforms.transform.BaseTransform`

   Combination of a series of transforms which is applicable to images in Imagenet.

   :param height: Height of the result
   :type height: int
   :param width: Width of the result
   :type width: int
   :param random_crop: whether to random crop
   :type random_crop: bool, default=False
   :param resize_side: desired shape after resize operation
   :type resize_side: int, default=256
   :param random_flip_left_right: whether to random flip left and right
   :type random_flip_left_right: bool, default=False
   :param mean_value: means for each channel
   :type mean_value: list, default=[0.0,0.0,0.0]
   :param scale: std value
   :type scale: float, default=1.0

   :returns: tuple of processed image and label


.. py:class:: TFSquadV1PostTransform(label_file, vocab_file, n_best_size=20, max_seq_length=384, max_query_length=64, max_answer_length=30, do_lower_case=True, doc_stride=128)

   Bases: :py:obj:`BaseTransform`

   Postprocess the predictions of bert on SQuAD.

   :param label_file: path of label file
   :type label_file: str
   :param vocab_file: path of vocabulary file
   :type vocab_file: str
   :param n_best_size: The total number of n-best predictions to generate in nbest_predictions.json
   :type n_best_size: int, default=20
   :param max_seq_length: The maximum total input sequence length after WordPiece tokenization.
                          Sequences longer than this will be truncated, shorter than this will be padded
   :type max_seq_length: int, default=384
   :param max_query_length: The maximum number of tokens for the question.
                            Questions longer than this will be truncated to this length
   :type max_query_length: int, default=64
   :param max_answer_length: The maximum length of an answer that can be generated. This is needed because
                             the start and end predictions are not conditioned on one another
   :type max_answer_length: int, default=30
   :param do_lower_case: Whether to lower case the input text.
                         Should be True for uncased models and False for cased models
   :type do_lower_case: bool, default=True
   :param doc_stride: When splitting up a long document into chunks,
                      how much stride to take between chunks
   :type doc_stride: int, default=128

   :returns: tuple of processed prediction and label

   .. py:method:: process_result(results)

      Get the processed results.


   .. py:method:: get_postprocess_result(sample)

      Get the post processed results.



.. py:class:: TFSquadV1ModelZooPostTransform(label_file, vocab_file, n_best_size=20, max_seq_length=384, max_query_length=64, max_answer_length=30, do_lower_case=True, doc_stride=128)

   Bases: :py:obj:`TFSquadV1PostTransform`

   Postprocess the predictions of bert on SQuADV1.1.

   See class TFSquadV1PostTransform for more details


.. py:class:: TensorflowResizeWithRatio(min_dim=800, max_dim=1365, padding=False, constant_value=0)

   Bases: :py:obj:`BaseTransform`

   Resize image with aspect ratio and pad it to max shape(optional).

   If the image is padded, the label will be processed at the same time.
   The input image should be np.array or tf.Tensor.

   :param min_dim: Resizes the image such that its smaller dimension == min_dim
   :type min_dim: int, default=800
   :param max_dim: Ensures that the image longest side doesn't exceed this value
   :type max_dim: int, default=1365
   :param padding: If true, pads image with zeros so its size is max_dim x max_dim
   :type padding: bool, default=False

   :returns: tuple of processed image and label


.. py:class:: ResizeTFTransform(size, interpolation='bilinear')

   Bases: :py:obj:`BaseTransform`

   Resize the input image to the given size.

   :param size: Size of the result
   :type size: list or int
   :param interpolation: Desired interpolation type,
                         support 'bilinear', 'nearest', 'bicubic'
   :type interpolation: str, default='bilinear'

   :returns: tuple of processed image and label


.. py:class:: RescaleTFTransform

   Bases: :py:obj:`BaseTransform`

   Scale the values of image to [0,1].

   :returns: tuple of processed image and label


.. py:class:: NormalizeTFTransform(mean=[0.0], std=[1.0], rescale=None)

   Bases: :py:obj:`BaseTransform`

   Normalize a image with mean and standard deviation.

   :param mean: means for each channel, if len(mean)=1, mean will be broadcasted to each channel,
                otherwise its length should be same with the length of image shape
   :type mean: list, default=[0.0]
   :param std: stds for each channel, if len(std)=1, std will be broadcasted to each channel,
               otherwise its length should be same with the length of image shape
   :type std: list, default=[1.0]

   :returns: tuple of processed image and label


.. py:class:: ParseDecodeCocoTransform

   Bases: :py:obj:`neural_compressor.experimental.data.transforms.BaseTransform`

   Coco decoding will be performed automatically from Neural Compressor v1.4.



.. py:class:: FILTERS(framework)

   Bases: :py:obj:`object`

   The filter register for all frameworks.

   :param framework: frameworks in ["tensorflow", "tensorflow_itex", "mxnet",
                     "onnxrt_qdq", "pytorch", "pytorch_ipex",
                     "pytorch_fx", "onnxrt_integerops",
                     "onnxrt_qlinearops", "onnxruntime"].
   :type framework: str


.. py:class:: Filter

   Bases: :py:obj:`object`

   The base class for transform.

   __call__ method is needed when write user specific transform.



.. py:function:: filter_registry(filter_type, framework)

   Register all transform subclasses.

   :param filter_type: fILTER registration name.
   :type filter_type: str
   :param framework: support 4 framework including 'tensorflow', 'pytorch', 'mxnet', 'onnxrt'.
   :type framework: str
   :param cls: The class of register.
   :type cls: class

   :returns: The class of register.
   :rtype: cls


.. py:class:: LabelBalanceCOCORecordFilter(size=1)

   Bases: :py:obj:`neural_compressor.data.filters.filter.Filter`

   The label balance filter for COCO Record.


