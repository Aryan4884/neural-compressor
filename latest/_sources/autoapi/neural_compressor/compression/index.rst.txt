:orphan:

:py:mod:`neural_compressor.compression`
=======================================

.. py:module:: neural_compressor.compression


Subpackages
-----------
.. toctree::
   :titlesonly:
   :maxdepth: 3

   distillation/index.rst
   pruner/index.rst


Submodules
----------
.. toctree::
   :titlesonly:
   :maxdepth: 1

   callbacks/index.rst


Package Contents
----------------

Classes
~~~~~~~

.. autoapisummary::

   neural_compressor.compression.QuantizationAwareTrainingCallbacks
   neural_compressor.compression.DistillationCallbacks
   neural_compressor.compression.PruningCallbacks
   neural_compressor.compression.WeightPruningConfig



Functions
~~~~~~~~~

.. autoapisummary::

   neural_compressor.compression.prepare_pruning



.. py:class:: QuantizationAwareTrainingCallbacks(conf=None, model=None)

   Bases: :py:obj:`BaseCallbacks`

   This is the class for callbacks of quantization aware training.

   This design is mainly for Quantization-Aware Training.
   In this class will apply all hooks for Quantization-Aware Training.

   .. 
.. py:class:: DistillationCallbacks(conf=None, model=None)

   Bases: :py:obj:`BaseCallbacks`

   Distillation class derived from Component class.

   Distillation class abstracted the pipeline of knowledge distillation,
   transfer the knowledge of the teacher model to the student model.

   :param conf: Distillation_Conf containing teacher model, distillation criterion etc.
   :param model: Student model.

   .. attribute:: _epoch_ran

      A integer indicating how much epochs ran.

   .. attribute:: eval_frequency

      The frequency for doing evaluation of the student model
      in terms of epoch.

   .. attribute:: best_score

      The best metric of the student model in the training.

   .. attribute:: best_model

      The best student model found in the training.

   ..    .. .. py:property:: criterion

      Getter of criterion.

      :returns: The criterion used in the distillation process.

   ..    .. .. py:property:: teacher_model

      Getter of the teacher model.

      :returns: The teacher model used in the distillation process.

   ..    .. .. py:property:: student_model

      Getter of the student model.

      :returns: The student model used in the distillation process.

   ..    .. .. py:property:: train_cfg

      Getter of the train configuration.

      :returns: The train configuration used in the distillation process.

   ..    .. py:method:: init_train_cfg()

      Initialize the training configuration.


   .. py:method:: create_criterion()

      Create the criterion for training.


   .. py:method:: generate_hooks()

      Register hooks for distillation.

      Register necessary hooks for distillation pipeline.



.. py:class:: PruningCallbacks(conf=None, model=None)

   Bases: :py:obj:`BaseCallbacks`

   This is the class for callbacks of pruning object.

   In this class will apply all hooks for Pruning.

   ..    .. py:method:: on_train_end()

      Be called after the end of training.


   .. py:method:: generate_hooks()

      Register hooks for pruning.



.. py:function:: prepare_pruning(config, model: torch.nn.Module, opt: torch.optim)

   Wrapper the model and optimizer to support all the pruning functionality.

   :param config: WeightPruningConfig
   :param model: The user's model
   :param opt: The user's optimizer
   :return: The modified model and optimizer


.. py:class:: WeightPruningConfig(pruning_configs=[{}], target_sparsity=0.9, pruning_type='snip_momentum', pattern='4x1', op_names=[], excluded_op_names=[], start_step=0, end_step=0, pruning_scope='global', pruning_frequency=1, min_sparsity_ratio_per_op=0.0, max_sparsity_ratio_per_op=0.98, sparsity_decay_type='exp', pruning_op_types=['Conv', 'Linear'], **kwargs)

   Similiar to torch optimizer's interface.

   Example::

       from neural_compressor.config import WeightPruningConfig

       config = WeightPruningConfig(
           local_configs,
           target_sparsity=0.8
       )
       prune = Pruning(config)
       prune.update_config(start_step=1, end_step=10)
       prune.model = self.model

   ..    .. .. py:property:: weight_compression

      Get weight_compression.

   .. 
