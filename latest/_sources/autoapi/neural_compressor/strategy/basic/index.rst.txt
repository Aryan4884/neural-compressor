:py:mod:`neural_compressor.strategy.basic`
==========================================

.. py:module:: neural_compressor.strategy.basic

.. autoapi-nested-parse::

   The basic tuning strategy.



Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   neural_compressor.strategy.basic.BasicTuneStrategy




.. py:class:: BasicTuneStrategy

   Bases: :py:obj:`neural_compressor.strategy.strategy.TuneStrategy`

   The basic tuning strategy.

   There are three stages executed by Basic strategy sequentially,
   and the tuning process ends once the condition meets the exit policy.

   ..    .. py:method:: distributed_next_tune_cfg_lst(comm)

      Generate and yield the next tuning config list with below order.

          1. OP Type Wise Tuning
          2. Fallback OP One by One
          3. Fallback Multiple OPs Accumulated

      :Yields: *tuning_config_list (list)* -- A list containing dicts of the tuning configuration for quantization.


   .. py:method:: next_tune_cfg()

      Generate and yield the next tuning config with below order.

          1. OP Type Wise Tuning: tries to quantize the OPs as many as possible
              and traverse all OP type wise tuning configs
          2. Fallback OP One by One: it performs high-precision OP (FP32, BF16 ...)
              fallbacks one by one based on the tuning config with the best result
              in the previous stage, and records the impact of each OP.
          3. Fallback Multiple OPs Accumulated: first sorted the OPs list
              according to the impact score in stage II, and tries to incrementally
              fallback multiple OPs to high precision according to the sorted OP list.

      :returns: A dict containing the tuning configuration for quantization.
      :rtype: tune_config (dict)



