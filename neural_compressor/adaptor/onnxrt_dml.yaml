## Copyright (c) 2021 Intel Corporation
##
## Licensed under the Apache License, Version 2.0 (the "License");
## you may not use this file except in compliance with the License.
## You may obtain a copy of the License at
##
##    http://www.apache.org/licenses/LICENSE-2.0
##
## Unless required by applicable law or agreed to in writing, software
## distributed under the License is distributed on an "AS IS" BASIS,
## WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
## See the License for the specific language governing permissions and
## limitations under the License.
##
#

-
  version:
    name: '1.13.1'
  int8: &ref_1_13 {
    'static': &ref_1_13_static {
      'Conv': {
        'weight':   &int8_sym_perchanneltensor_minmax {
                    'dtype': ['int8'],
                    'scheme': ['sym'],
                    'granularity': ['per_channel', 'per_tensor'],
                    'algorithm': ['minmax']
                    },
        'activation': &uint8_asym_pertensor_minmax {
                    'dtype': ['uint8'],
                    'scheme': ['asym'],
                    'granularity': ['per_tensor'],
                    'algorithm': ['minmax']
                    },
        'mode': ['QDQ', 'QLinear']
      },
      'Gather': {
        'weight':   &uint8_asym_perchanneltensor_minmax {
                    'dtype': ['uint8'],
                    'scheme': ['asym'],
                    'granularity': ['per_channel', 'per_tensor'],
                    'algorithm': ['minmax']
                    }, 
        'activation': *uint8_asym_pertensor_minmax,
        'mode': ['QDQ', 'QLinear']
      },
      'MatMul': {
        'weight':   &int8_sym_pertensor_minmax {
                    'dtype': ['int8'],
                    'scheme': ['sym'],
                    'granularity': ['per_tensor'],
                    'algorithm': ['minmax']
                    }, 
        'activation': *uint8_asym_pertensor_minmax,
        'mode': ['QDQ', 'QLinear']
      },
      'Mul': &default_static_qlinear {
        'weight':   *int8_sym_pertensor_minmax,
        'activation': *uint8_asym_pertensor_minmax,
        'mode': ['QLinear']
      },
      'Relu': *default_static_qlinear_qdq, 
      'Clip': *default_static_qlinear_qdq,
      'MaxPool': *default_static_qlinear_qdq,
      'Add': *default_static_qlinear,
    },
    'dynamic': &ref_1_13_dynamic {
      'Conv': {
        'weight':   *uint8_asym_perchanneltensor_minmax,
        'activation': *uint8_asym_pertensor_minmax
      },
      'MatMul': &default_dynamic {
        'weight': *int8_sym_pertensor_minmax,
        'activation': *uint8_asym_pertensor_minmax
      },
      'Gather': *default_dynamic,
    }
  }
  fp16: &common_fp16 ['Abs', 'Acos', 'Acosh', 'Add', 'Affine', 'ArgMax', 'ArgMin', 'Asin',
    'Asinh', 'Atan', 'Atanh', 'AveragePool', 'BatchNormalization', 'Ceil', 'Celu', 'Clip',
    'Concat', 'ConstantOfShape', 'Conv', 'ConvTranspose', 'Cos', 'Cosh', 'Crop', 'CumSum',
    'DepthToSpace', 'Div', 'Dropout', 'Einsum', 'Elu', 'Equal', 'Erf', 'Exp', 'Expand',
    'EyeLike', 'Flatten', 'Floor', 'GRU', 'Gather', 'GatherElements', 'GatherND', 'Gemm',
    'GlobalAveragePool', 'GlobalLpPool', 'GlobalMaxPool', 'Greater', 'GreaterOrEqual',
    'HardSigmoid', 'Hardmax', 'Identity', 'ImageScaler', 'InstanceNormalization', 'IsNaN',
    'LRN', 'LSTM', 'LeakyRelu', 'Less', 'LessOrEqual', 'Log', 'LogSoftmax', 'LpNormalization',
    'LpPool', 'MatMul', 'Max', 'MaxPool', 'MaxRoiPool', 'MaxUnpool', 'Mean',
    'MeanVarianceNormalization', 'MemcpyFromHost', 'MemcpyToHost', 'Min', 'Mod', 'Mul',
    'Neg', 'OneHot', 'PRelu', 'Pad', 'ParametricSoftplus', 'Pow', 'RNN', 'Range', 'Reciprocal',
    'ReduceL1', 'ReduceL2', 'ReduceLogSum', 'ReduceLogSumExp', 'ReduceMax', 'ReduceMean',
    'ReduceMin', 'ReduceProd', 'ReduceSum', 'ReduceSumSquare', 'Relu', 'Reshape', 'Resize',
    'ReverseSequence', 'RoiAlign', 'Round', 'ScaledTanh', 'Scatter', 'ScatterElements',
    'ScatterND', 'Selu', 'Shrink', 'Sigmoid', 'Sign', 'Sin', 'Sinh', 'Slice', 'Softmax',
    'Softplus', 'Softsign', 'SpaceToDepth', 'Split', 'Sqrt', 'Squeeze', 'Sub', 'Sum',
    'Tan', 'Tanh', 'ThresholdedRelu', 'Tile', 'TopK', 'Transpose', 'Trilu', 'Unsqueeze',
    'Upsample', 'Where', 'Attention', 'BeamSearch', 'BiasDropout', 'BiasGelu', 'BiasSoftmax',
    'BitmaskBiasDropout', 'BitmaskDropout', 'ComplexMul', 'ComplexMulConj', 'DecoderAttention',
    'EmbedLayerNormalization', 'FastGelu', 'FusedMatMul', 'Gelu', 'GreedySearch', 'Inverse',
    'Irfft', 'LongformerAttention', 'Rfft', 'SkipLayerNormalization', 'TransposeMatMul', 'Trilu']

 
  recipes: &default_optimization
    graph_optimization:   # from onnxruntime graph_optimization_level
      level: ['DISABLE_ALL', 'ENABLE_BASIC', 'ENABLE_EXTENDED', 'ENABLE_ALL']

-
  version:
    name: 'default'
  int8: *ref_1_13
  recipes:
    <<: *default_optimization
